{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ece54c-a59a-4b8b-b0f3-427278ff98fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage1/kaiyuan/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598046541213989}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I've been waiting for a HuggingFace course my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5edaa53-a805-454c-9522-7a9559270f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598046541213989},\n",
       " {'label': 'NEGATIVE', 'score': 0.9994558691978455}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier([\"I've been waiting for a HuggingFace course my whole life.\", \"I hate this so much!\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d15e78b-fd48-42b6-8e56-80f9b85eb1a5",
   "metadata": {},
   "source": [
    "***Zero-shot classification***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f7c4326-f1ab-46f3-9927-3b7ff2192c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445962071418762, 0.111976258456707, 0.04342758655548096]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2961856-e536-4fbc-b838-0b1b6f9880e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision d7645e1 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'games', 'politics'],\n",
       " 'scores': [0.7658213376998901,\n",
       "  0.10153231024742126,\n",
       "  0.09326932579278946,\n",
       "  0.0393771268427372]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels=[\"education\", \"politics\", \"business\", \"games\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75387d6-4036-4ba3-a716-3a84ad12ab3b",
   "metadata": {},
   "source": [
    "***Text generation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b583f51-88cc-4b61-9319-b3e43060cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to openai-community/gpt2 and revision 607a30d (https://huggingface.co/openai-community/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to control the flow of the virtual world.\\n\\nBefore we begin, you will need to know how to use the mouse to move objects. You will also need to know how to create a virtual environment in a specific order.\\n\\nThe purpose of this course is to develop a system to control the flow of virtual worlds in a simple and easy manner.\\n\\nHere is a diagram of our system.\\n\\nBefore we begin, you will need to understand how to set up a virtual environment.\\n\\nYou will need to know how to create a virtual environment.\\n\\nWe have already defined a set of rules to govern what can be done with virtual worlds. We will then make use of those rules to create a virtual reality environment.\\n\\nWe will also show you how to create a virtual environment in a very simple and easy manner.\\n\\nNow, we will get to how to create a virtual environment in a very simple and easy manner.\\n\\nIn this course, we will create a virtual environment in a very simple and easy manner.\\n\\nLet us start with the basics first.\\n\\nWe will learn how to control the flow of virtual worlds.\\n\\nWe will learn how to create a virtual environment in a very simple and easy manner.\\n'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\")\n",
    "generator(\"In this course, we will teach you how to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ceed3d-879b-4411-9a6e-6d3aba4f7e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to use the latest and most effective strategies to solve problems in a productive and positive way. You will learn how to think creatively and solve problems in a productive way. We will also teach you how to take positive action in order to achieve your goals.\\n\\n## What is Statistics?\\n\\nStatistics is the study of the collection, analysis, interpretation, presentation, and organization of data. It is used to analyze and interpret data in order to make informed decisions.\\n\\n## What is Data?\\n\\nData is a collection of information that is used to answer questions or solve problems. It can be quantitative (numbers) or qualitative (descriptions of people or events).\\n\\n## What is a Hypothesis?\\n\\nA hypothesis is a proposed explanation for a set of observations or data. It is used to test a theory or hypothesis and to determine whether it is correct or not.\\n\\n## What is an Experiment?\\n\\nAn experiment is a study designed to test a hypothesis. It involves collecting data and analyzing it in order to determine whether the hypothesis is correct or not.\\n\\n## What is the Scientific Method?\\n\\nThe scientific method is a systematic approach to gathering, analyzing, and interpreting data. It involves forming a hypothesis, designing an experiment, collecting data'},\n",
       " {'generated_text': \"In this course, we will teach you how to become a doctor. What are the skills you will need, and what kind of education and training do you need?\\n\\n\\nMedical School\\n\\nMedical school is a two-year program that prepares students for residency and/or fellowship programs.\\n\\nA residency is a program that teaches students how to provide care to patients, while a fellowship is a program that trains doctors to serve the general health care system and to manage the health care system as a whole. The training required for a residency or fellowship varies greatly, depending on the type of specialty.\\n\\nRegistration, Fellowship, and Residency\\n\\nRegistration is the first step in a doctor's career. Registration is the process of becoming a licensed physician in a state. Registration is the process of becoming a licensed physician in a state.\\n\\nFellowship is a program that trains doctors to serve the general health care system and to manage the health care system as a whole. Fellowship is a program that trains doctors to serve the general health care system and to manage the health care system as a whole.\\n\\nResidency is a program that trains doctors to provide care to patients.\\n\\n\\nMedical School\\n\\nMedical school is a two-year program that prepares students for residency and/or fellowship programs.\\n\"}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model = \"HuggingFaceTB/SmolLM2-360M\")\n",
    "generator(\n",
    "    \"In this course, we will teach you how to\",\n",
    "    truncation=True,\n",
    "    max_length = 30,\n",
    "    num_return_sequences = 2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1aeb18-8aea-4246-b4a2-7ea09b40b02e",
   "metadata": {},
   "source": [
    "***Mask filling***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d54804d1-717a-40b8-aa61-caa92659797b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilroberta-base and revision fb53ab8 (https://huggingface.co/distilbert/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at distilbert/distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.19619813561439514,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models.'},\n",
       " {'score': 0.04052717983722687,\n",
       "  'token': 38163,\n",
       "  'token_str': ' computational',\n",
       "  'sequence': 'This course will teach you all about computational models.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "unmasker(\"This course will teach you all about <mask> models.\", top_k = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27bf1b0-c7f7-4a4c-b7cf-5bbe12be4191",
   "metadata": {},
   "source": [
    "***Named entity recognition***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24cc7283-6af8-48ea-a12f-1a2ab1d07f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision 4c53496 (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': np.float32(0.9842253),\n",
       "  'word': 'Kaiyuan',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': np.float32(0.99003494),\n",
       "  'word': 'ViDi',\n",
       "  'start': 33,\n",
       "  'end': 37},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.90683484),\n",
       "  'word': 'UCDavis',\n",
       "  'start': 41,\n",
       "  'end': 48},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': np.float32(0.9756522),\n",
       "  'word': 'CA',\n",
       "  'start': 50,\n",
       "  'end': 52}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities = True)\n",
    "ner(\"My name is Kaiyuan and I work at ViDi in UCDavis, CA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8f2a9-b7bb-46f8-9dcc-e0e33140e711",
   "metadata": {},
   "source": [
    "***Question answering***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22d6176d-0061-426d-94f6-bfc3b54c3e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 564e9b5 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.24891121685504913, 'start': 33, 'end': 37, 'answer': 'ViDi'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "question_answerer(\n",
    "    question = \"Where do I work?\",\n",
    "    context = \"My name is Kaiyuan and I work at ViDi in UCDavis, CA.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35867e0-48c2-4799-973a-cc4815a4f06e",
   "metadata": {},
   "source": [
    "***Summarization***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b08a8fd-7781-4f28-b94b-a5e768713caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' America has changed dramatically during recent years . The number of engineering graduates in the U.S. has declined in traditional engineering disciplines such as mechanical, civil,    electrical, chemical, and aeronautical engineering . Rapidly developing economies such as China and India continue to encourage and advance the teaching of engineering .'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")\n",
    "summarizer(\n",
    "    \"\"\"\n",
    "    America has changed dramatically during recent years. Not only has the number of \n",
    "    graduates in traditional engineering disciplines such as mechanical, civil, \n",
    "    electrical, chemical, and aeronautical engineering declined, but in most of \n",
    "    the premier American universities engineering curricula now concentrate on \n",
    "    and encourage largely the study of engineering science. As a result, there \n",
    "    are declining offerings in engineering subjects dealing with infrastructure, \n",
    "    the environment, and related issues, and greater concentration on high \n",
    "    technology subjects, largely supporting increasingly complex scientific \n",
    "    developments. While the latter is important, it should not be at the expense \n",
    "    of more traditional engineering.\n",
    "\n",
    "    Rapidly developing economies such as China and India, as well as other \n",
    "    industrial countries in Europe and Asia, continue to encourage and advance \n",
    "    the teaching of engineering. Both China and India, respectively, graduate \n",
    "    six and eight times as many traditional engineers as does the United States. \n",
    "    Other industrial countries at minimum maintain their output, while America \n",
    "    suffers an increasingly serious decline in the number of engineering graduates \n",
    "    and a lack of well-educated engineers.\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4fbc9c-1300-42ca-970b-a6ba6cecd992",
   "metadata": {},
   "source": [
    "***Translation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04d8e622-7d99-45e1-acc9-6a1ecb74d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers[sentencepiece] in /home/kkyliao/.local/lib/python3.8/site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers[sentencepiece]) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /home/kkyliao/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.32.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kkyliao/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kkyliao/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/kkyliao/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kkyliao/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/kkyliao/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /home/kkyliao/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/kkyliao/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/kkyliao/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (4.64.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/kkyliao/.local/lib/python3.8/site-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Requirement already satisfied: protobuf in /usr/lib/python3/dist-packages (from transformers[sentencepiece]) (3.6.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/kkyliao/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece]) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/kkyliao/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece]) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/kkyliao/.local/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers[sentencepiece]) (1.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kkyliao/.local/lib/python3.8/site-packages (from requests->transformers[sentencepiece]) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers[sentencepiece]) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kkyliao/.local/lib/python3.8/site-packages (from requests->transformers[sentencepiece]) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers[sentencepiece]) (2019.11.28)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[sentencepiece]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "480a2132-972c-4eca-989d-f4b1e22a656a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage1/kaiyuan/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/media/storage1/kaiyuan/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "translator(\"Ce cours est produit par Hugging Face.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1e2597-7a8e-4c14-90e6-0be1df1fa390",
   "metadata": {},
   "source": [
    "***Image classification***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81f32a6-26ff-48b4-a48b-cf9850faed1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/storage1/kaiyuan/anaconda3/envs/LLMcourse/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'lynx, catamount', 'score': 0.43350037932395935}, {'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor', 'score': 0.034796182066202164}, {'label': 'snow leopard, ounce, Panthera uncia', 'score': 0.03240185230970383}, {'label': 'Egyptian cat', 'score': 0.023944756016135216}, {'label': 'tiger cat', 'score': 0.022889157757163048}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "image_classifier = pipeline(\n",
    "    task = \"image-classification\", model = \"google/vit-base-patch16-224\"\n",
    ")\n",
    "\n",
    "result = image_classifier(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cef985-b3e0-4c6a-9f32-5a705518c04d",
   "metadata": {},
   "source": [
    "***Automatic speech recognition***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be9dc4b-bda6-493e-b428-a8cb0423f335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "`return_token_timestamps` is deprecated for WhisperFeatureExtractor and will be removed in Transformers v5. Use `return_attention_mask` instead, as the number of frames can be inferred from it.\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(\n",
    "    task = \"automatic-speech-recognition\", model = \"openai/whisper-large-v3\"\n",
    ")\n",
    "\n",
    "result = transcriber(\n",
    "    \"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\"\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533af22d-84ca-47f2-b9dc-bd5a659faec2",
   "metadata": {},
   "source": [
    "***Bias and Limitations***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f5f0ce-a192-4c0e-b610-1ed3b5946d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
      "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "result = unmasker(\"This man works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])\n",
    "\n",
    "result = unmasker(\"This woman works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc53ceb-b1d2-42f1-bc74-37a21ae3132f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (LLMcourse)",
   "language": "python",
   "name": "llmcourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
